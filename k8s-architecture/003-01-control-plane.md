# 1. 컨트롤 플레인 노드 수
190대 규모 클러스터에서 컨트롤 플레인 설계는 가용성과 성능에 직접적인 영향을 미칩니다.

## 1.1 배경 설명
컨트롤 플레인은 API Server, Controller Manager, Scheduler, etcd로 구성됩니다. 
노드 수가 많을수록 API Server 부하가 증가하고, 빅데이터 워크로드(특히 Spark/Flink)는 Pod 생성/삭제가 빈번하여 컨트롤 플레인 부하가 높습니다.

알겠습니다! 아키텍처 레벨에서 단계별로 진행하겠습니다. 코드는 요청하시기 전까지 작성하지 않을게요.

---

## 아키텍처 설계 로드맵

진행 순서를 먼저 공유드립니다:

1. **클러스터 아키텍처** - 컨트롤 플레인, etcd, API LB
2. **네트워크 아키텍처** - 물리망 구성, Cilium 설계
3. **스토리지 아키텍처** - NVMe 활용, Isilon 연동, MinIO 연결
4. **노드 역할 분리** - 워크로드별 노드 그룹 설계
5. **멀티테넌시 전략** - 4개 팀 격리 방안
6. **워크로드별 고려사항** - Spark, Flink, Kafka 등 배치 전략
7. **관측성(Observability)** - 모니터링/로깅 아키텍처

---

## 1단계: 클러스터 아키텍처

### 1-1. 컨트롤 플레인 노드 수

190대 규모 클러스터에서 컨트롤 플레인 설계는 가용성과 성능에 직접적인 영향을 미칩니다.

**옵션**

| 옵션 | 구성 | 장점 | 단점 |
|------|------|------|------|
| **A. 3대** | 컨트롤 플레인 3대 | 리소스 절약, 운영 단순 | 190대+빅데이터 워크로드에는 부하 집중 우려, 1대 장애시 쿼럼 여유 없음 |
| **B. 5대** | 컨트롤 플레인 5대 | 2대 동시 장애 허용, 부하 분산, 롤링 업그레이드 안전 | 리소스 사용 증가 |
| **C. 7대** | 컨트롤 플레인 7대 | 최대 가용성, 부하 분산 극대화 | 과도할 수 있음, etcd 합의 지연 가능성 |

**베스트 프랙티스 기반 권장**

190대 규모 + Spark/Flink의 동적 Pod 생성 패턴을 고려하면 **옵션 B (5대)**를 권장합니다. 대부분의 대규모 프로덕션 클러스터에서 표준으로 사용되며, 유지보수 중에도 쿼럼이 안정적으로 유지됩니다.

---

### 1-2. etcd 배치 전략

**배경 설명**

etcd는 클러스터의 모든 상태를 저장하는 핵심 컴포넌트입니다. 디스크 I/O 성능이 etcd 성능에 직접적인 영향을 미치며, API Server와 리소스 경합이 발생할 수 있습니다.

**옵션**

| 옵션 | 구성 | 장점 | 단점 |
|------|------|------|------|
| **A. Stacked (동일 노드)** | 컨트롤 플레인 노드에 etcd 함께 배치 | 구성 단순, 노드 수 절약, Kubespray 기본 구성 | 리소스 경합 가능, API Server와 etcd 동시 장애 |
| **B. External (분리)** | etcd 전용 노드 3~5대 별도 구성 | 리소스 격리, etcd 성능 최적화, 독립적 확장/관리 | 추가 노드 필요 (3~5대), 구성 복잡도 증가 |

**베스트 프랙티스 기반 권장**

빅데이터 워크로드로 인한 높은 API 호출 빈도를 고려하면 **옵션 B (External etcd)**가 이상적이지만, 현재 노드 스펙(48코어, 768GB)이 충분히 여유있고 NVMe SSD를 etcd 전용으로 할당할 수 있다면 **옵션 A (Stacked)**도 충분히 가능합니다.

만약 옵션 A를 선택하신다면, 컨트롤 플레인 노드에서 NVMe SSD 중 하나를 etcd 전용으로 마운트하는 것을 권장합니다.

---

### 1-3. API Server 로드밸런서

**배경 설명**

모든 워커 노드의 kubelet과 kubectl, 그리고 Spark/Airflow 등의 Operator들이 API Server에 접근합니다. 고가용성을 위해 여러 API Server 앞에 로드밸런서가 필요합니다.

**옵션**

| 옵션 | 구성 | 장점 | 단점 |
|------|------|------|------|
| **A. 외부 하드웨어 LB** | F5, Citrix 등 기존 인프라 활용 | 검증된 안정성, 기존 운영 체계 활용, 성능 우수 | 별도 비용/리소스, 네트워크팀 협업 필요 |
| **B. HAProxy + Keepalived** | VM 또는 물리 서버 2대에 구성 | 오픈소스, 유연한 설정, 비용 없음 | 별도 관리 포인트, 직접 HA 구성 필요 |
| **C. kube-vip** | 컨트롤 플레인 노드에서 VIP 관리 | 추가 인프라 불필요, Kubespray 지원 | 상대적으로 신규, 복잡한 환경에서 제한적 |

**베스트 프랙티스 기반 권장**

190대 규모 프로덕션이라면 **옵션 A (외부 하드웨어 LB)**가 있다면 가장 안정적입니다. 만약 없다면 **옵션 B (HAProxy + Keepalived)**가 검증된 선택입니다. 옵션 C는 소규모에서는 좋지만 이 규모에서는 권장하지 않습니다.

---

## 결정 요청

다음 단계로 넘어가기 전에 위 3가지에 대한 결정을 부탁드립니다:

1. **컨트롤 플레인 노드 수**: A(3대) / B(5대) / C(7대)?
2. **etcd 배치**: A(Stacked) / B(External)?
3. **API Server LB**: A(외부 LB) / B(HAProxy+Keepalived) / C(kube-vip)?

추가로 확인이 필요하거나 다른 고려사항이 있으시면 말씀해주세요!
